# Article-Summarization

I compared five different LLM models to see how well they could summarize 30 different genetics articles obtained using the newspaper3k package from US News and World Report. I created the ground truth for the summaries by prompting Chat-GPT4.0 to generate the summaries in a specific manner. I used the t5-small, Pegasus-xsum, Pegasus-Large, Pegasus-CNN/DailyMail and BART-Large models to generate summaries and compared them to the ground truth. I evaluated the precision, recall and f1-score of the models using ROUGE. The BART model exhibited the best performance. The models generally had a similar performance with the exception of the Pegasus-xsum model that was good at creating short summaries, but when parameters were tweaked to create longer summaries did not perform well. However, from a qualitative standpoint the summaries created by the Pegasus-xsum model were the best written due to the brevity of the summaries. Overall, the summaries generated were much shorter than the Chat-GPT generated summaries, which resulted in low recall scores.
